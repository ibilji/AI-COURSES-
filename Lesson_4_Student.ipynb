{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5789bc3-b1ae-42c7-94a8-2ef4f89946fc",
   "metadata": {},
   "source": [
    "# Lesson 4: Persistence and Streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5762271-8736-4e94-9444-8c92bd0e8074",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "_ = load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0168aee-bce9-4d60-b827-f86a88187e31",
   "metadata": {
    "height": 115
   },
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "from typing import TypedDict, Annotated\n",
    "import operator\n",
    "from langchain_core.messages import AnyMessage, SystemMessage, HumanMessage, ToolMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da06a64f-a2d5-4a66-8090-9ada0930c684",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "tool = TavilySearchResults(max_results=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2589c5b6-6cc2-4594-9a17-dccdcf676054",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage], operator.add]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c033522-d2fc-41ac-8e3c-5e35872bf88d",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "\n",
    "memory = SqliteSaver.from_conn_string(\":memory:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ba84ec-c172-4de7-ac55-e3158a531b23",
   "metadata": {
    "height": 574
   },
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self, model, tools, checkpointer, system=\"\"):\n",
    "        self.system = system\n",
    "        graph = StateGraph(AgentState)\n",
    "        graph.add_node(\"llm\", self.call_openai)\n",
    "        graph.add_node(\"action\", self.take_action)\n",
    "        graph.add_conditional_edges(\"llm\", self.exists_action, {True: \"action\", False: END})\n",
    "        graph.add_edge(\"action\", \"llm\")\n",
    "        graph.set_entry_point(\"llm\")\n",
    "        self.graph = graph.compile(checkpointer=checkpointer)\n",
    "        self.tools = {t.name: t for t in tools}\n",
    "        self.model = model.bind_tools(tools)\n",
    "\n",
    "    def call_openai(self, state: AgentState):\n",
    "        messages = state['messages']\n",
    "        if self.system:\n",
    "            messages = [SystemMessage(content=self.system)] + messages\n",
    "        message = self.model.invoke(messages)\n",
    "        return {'messages': [message]}\n",
    "\n",
    "    def exists_action(self, state: AgentState):\n",
    "        result = state['messages'][-1]\n",
    "        return len(result.tool_calls) > 0\n",
    "\n",
    "    def take_action(self, state: AgentState):\n",
    "        tool_calls = state['messages'][-1].tool_calls\n",
    "        results = []\n",
    "        for t in tool_calls:\n",
    "            print(f\"Calling: {t}\")\n",
    "            result = self.tools[t['name']].invoke(t['args'])\n",
    "            results.append(ToolMessage(tool_call_id=t['id'], name=t['name'], content=str(result)))\n",
    "        print(\"Back to the model!\")\n",
    "        return {'messages': results}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876d5092-b8ef-4e38-b4d7-0e80c609bf7a",
   "metadata": {
    "height": 132
   },
   "outputs": [],
   "source": [
    "prompt = \"\"\"You are a smart research assistant. Use the search engine to look up information. \\\n",
    "You are allowed to make multiple calls (either together or in sequence). \\\n",
    "Only look up information when you are sure of what you want. \\\n",
    "If you need to look up some information before asking a follow up question, you are allowed to do that!\n",
    "\"\"\"\n",
    "model = ChatOpenAI(model=\"gpt-4o\")\n",
    "abot = Agent(model, [tool], system=prompt, checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10084a02-2928-4945-9f7c-ad3f5b33caf7",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "messages = [HumanMessage(content=\"What is the weather in sf?\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "714d1205-f8fc-4912-b148-2a45da99219c",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "thread = {\"configurable\": {\"thread_id\": \"1\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83588e70-254f-4f83-a510-c8ae81e729b0",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "for event in abot.graph.stream({\"messages\": messages}, thread):\n",
    "    for v in event.values():\n",
    "        print(v['messages'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb3ef4c-58b3-401b-b104-0d51e553d982",
   "metadata": {
    "height": 98
   },
   "outputs": [],
   "source": [
    "messages = [HumanMessage(content=\"What about in la?\")]\n",
    "thread = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "for event in abot.graph.stream({\"messages\": messages}, thread):\n",
    "    for v in event.values():\n",
    "        print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3293b7-a50c-43c8-a022-8975e1e444b8",
   "metadata": {
    "height": 98
   },
   "outputs": [],
   "source": [
    "messages = [HumanMessage(content=\"Which one is warmer?\")]\n",
    "thread = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "for event in abot.graph.stream({\"messages\": messages}, thread):\n",
    "    for v in event.values():\n",
    "        print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0722c3d4-4cbf-43bf-81b0-50f634c4ce61",
   "metadata": {
    "height": 98
   },
   "outputs": [],
   "source": [
    "messages = [HumanMessage(content=\"Which one is warmer?\")]\n",
    "thread = {\"configurable\": {\"thread_id\": \"2\"}}\n",
    "for event in abot.graph.stream({\"messages\": messages}, thread):\n",
    "    for v in event.values():\n",
    "        print(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace59a36-3941-459e-b9d1-ac5a4a1ed3ae",
   "metadata": {},
   "source": [
    "## Streaming tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2f82fe-3ec4-4917-be51-9fb10d1317fa",
   "metadata": {
    "height": 81
   },
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.aiosqlite import AsyncSqliteSaver\n",
    "\n",
    "memory = AsyncSqliteSaver.from_conn_string(\":memory:\")\n",
    "abot = Agent(model, [tool], system=prompt, checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0fe1c7-77e2-499c-a2f9-1f739bb6ddf0",
   "metadata": {
    "height": 200
   },
   "outputs": [],
   "source": [
    "messages = [HumanMessage(content=\"What is the weather in SF?\")]\n",
    "thread = {\"configurable\": {\"thread_id\": \"4\"}}\n",
    "async for event in abot.graph.astream_events({\"messages\": messages}, thread, version=\"v1\"):\n",
    "    kind = event[\"event\"]\n",
    "    if kind == \"on_chat_model_stream\":\n",
    "        content = event[\"data\"][\"chunk\"].content\n",
    "        if content:\n",
    "            # Empty content in the context of OpenAI means\n",
    "            # that the model is asking for a tool to be invoked.\n",
    "            # So we only print non-empty content\n",
    "            print(content, end=\"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f303b1-a4d0-408c-8cc0-515ff980717f",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "650b4032",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "_ = load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dea9b1cb",
   "metadata": {
    "height": 115
   },
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "from typing import TypedDict, Annotated\n",
    "import operator\n",
    "from langchain_core.messages import AnyMessage, SystemMessage, HumanMessage, ToolMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4172f4f7",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "tool = TavilySearchResults(max_results=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2caa97d",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage], operator.add]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c10dd4f",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "\n",
    "memory = SqliteSaver.from_conn_string(\":memory:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f4ab6a9",
   "metadata": {
    "height": 591
   },
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self, model, tools, checkpointer, system=\"\"):\n",
    "        self.system = system\n",
    "        graph = StateGraph(AgentState)\n",
    "        graph.add_node(\"llm\", self.call_openai)\n",
    "        graph.add_node(\"action\", self.take_action)\n",
    "        graph.add_conditional_edges(\"llm\", self.exists_action, {True: \"action\", False: END})\n",
    "        graph.add_edge(\"action\", \"llm\")\n",
    "        graph.set_entry_point(\"llm\")\n",
    "        self.graph = graph.compile(checkpointer=checkpointer)\n",
    "        self.tools = {t.name: t for t in tools}\n",
    "        self.model = model.bind_tools(tools)\n",
    "\n",
    "    def call_openai(self, state: AgentState):\n",
    "        messages = state['messages']\n",
    "        if self.system:\n",
    "            messages = [SystemMessage(content=self.system)] + messages\n",
    "        message = self.model.invoke(messages)\n",
    "        return {'messages': [message]}\n",
    "\n",
    "    def exists_action(self, state: AgentState):\n",
    "        result = state['messages'][-1]\n",
    "        return len(result.tool_calls) > 0\n",
    "\n",
    "    def take_action(self, state: AgentState):\n",
    "        tool_calls = state['messages'][-1].tool_calls\n",
    "        results = []\n",
    "        for t in tool_calls:\n",
    "            print(f\"Calling: {t}\")\n",
    "            result = self.tools[t['name']].invoke(t['args'])\n",
    "            results.append(ToolMessage(tool_call_id=t['id'], name=t['name'], content=str(result)))\n",
    "        print(\"Back to the model!\")\n",
    "        return {'messages': results}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "17183d63",
   "metadata": {
    "height": 149
   },
   "outputs": [],
   "source": [
    "prompt = \"\"\"You are a smart research assistant. Use the search engine to look up information. \\\n",
    "You are allowed to make multiple calls (either together or in sequence). \\\n",
    "Only look up information when you are sure of what you want. \\\n",
    "If you need to look up some information before asking a follow up question, you are allowed to do that!\n",
    "\"\"\"\n",
    "model = ChatOpenAI(model=\"gpt-4o\")\n",
    "abot = Agent(model, [tool], system=prompt, checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa7bead6",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "messages = [HumanMessage(content=\"What is the weather in sf?\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f43df1f6",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "thread = {\"configurable\": {\"thread_id\": \"1\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "380c4d40",
   "metadata": {
    "height": 64
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_bmfLa92f6oAIKN9KvXtqbKDz', 'function': {'arguments': '{\"query\":\"current weather in San Francisco\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 22, 'prompt_tokens': 151, 'total_tokens': 173, 'prompt_tokens_details': {'cached_tokens': 0, 'audio_tokens': 0}, 'completion_tokens_details': {'reasoning_tokens': 0, 'audio_tokens': 0, 'accepted_prediction_tokens': 0, 'rejected_prediction_tokens': 0}}, 'model_name': 'gpt-4o', 'system_fingerprint': 'fp_831e067d82', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-ad5687a3-44c1-4c18-872a-a6d7861af98f-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'current weather in San Francisco'}, 'id': 'call_bmfLa92f6oAIKN9KvXtqbKDz'}])]\n",
      "Calling: {'name': 'tavily_search_results_json', 'args': {'query': 'current weather in San Francisco'}, 'id': 'call_bmfLa92f6oAIKN9KvXtqbKDz'}\n",
      "Back to the model!\n",
      "[ToolMessage(content='[{\\'url\\': \\'https://www.weather25.com/north-america/usa/california/san-francisco?page=month&month=July\\', \\'content\\': \\'weather25.com\\\\nSearch\\\\nweather in United States\\\\nRemove from your favorite locations\\\\nAdd to my locations\\\\nShare\\\\nweather in United States\\\\n\\\\n# San Francisco weather in July 2025\\\\n\\\\nOvercast\\\\nOvercast\\\\nMist\\\\nPatchy rain possible\\\\nOvercast\\\\nClear\\\\nClear\\\\nSunny\\\\nClear\\\\nClear\\\\nClear\\\\nSunny\\\\nSunny\\\\nSunny\\\\n\\\\n## The average weather in San Francisco in July\\\\n\\\\nThe temperatures in San Francisco in July are comfortable with low of 14°C and and high up to 25°C. [...] | 13 Partly cloudy 19° /12° | 14 Partly cloudy 20° /13° | 15 Partly cloudy 20° /13° | 16 Sunny 20° /13° | 17 Overcast 15° /14° | 18 Overcast 15° /13° | 19 Mist 14° /12° |\\\\n| 20 Patchy rain possible 17° /13° | 21 Overcast 18° /14° | 22 Sunny 17° /14° | 23 Sunny 18° /13° | 24 Sunny 17° /13° | 25 Sunny 17° /14° | 26 Sunny 18° /13° |\\\\n| 27 Sunny 19° /13° | 28 Sunny 21° /14° | 29 Sunny 20° /15° | 30 Sunny 19° /14° | 31 Partly cloudy 21° /14° |  |  | [...] | Sun | Mon | Tue | Wed | Thu | Fri | Sat |\\\\n| --- | --- | --- | --- | --- | --- | --- |\\\\n|  |  | 1 Cloudy 20° /12° | 2 Partly cloudy 20° /12° | 3 Sunny 20° /12° | 4 Sunny 20° /12° | 5 Sunny 20° /13° |\\\\n| 6 Sunny 19° /13° | 7 Mist 19° /12° | 8 Sunny 20° /12° | 9 Partly cloudy 20° /13° | 10 Partly cloudy 21° /13° | 11 Sunny 22° /13° | 12 Sunny 20° /13° |\\'}, {\\'url\\': \\'https://weather.com/weather/today/l/San+Francisco+CA+USCA0987:1:US\\', \\'content\\': \"## Recent Locations\\\\n\\\\nMenu\\\\n\\\\n## Weather Forecasts\\\\n\\\\n## Radar & Maps\\\\n\\\\n## News & Media\\\\n\\\\n## Products & Account\\\\n\\\\n## Lifestyle\\\\n\\\\n### Specialty Forecasts\\\\n\\\\n# San Francisco, CA\\\\n\\\\n## Small Craft Advisory\\\\n\\\\n# Hourly Weather-San Francisco, CA\\\\n\\\\n## Now\\\\n\\\\nCloudy\\\\n\\\\n## 5 am\\\\n\\\\nCloudy\\\\n\\\\n## 6 am\\\\n\\\\nCloudy\\\\n\\\\n## 7 am\\\\n\\\\nCloudy\\\\n\\\\nChart small gif\\\\n\\\\n## Don\\'t Miss\\\\n\\\\n## Seasonal Hub\\\\n\\\\n# 10 Day Weather-San Francisco, CA\\\\n\\\\n## Today\\\\n\\\\n## Day\\\\n\\\\nCloudy skies this morning will become partly cloudy this afternoon. High 66F. Winds W at 10 to 20 mph. [...] ## Night\\\\n\\\\nPartly cloudy skies this evening will become overcast overnight. Low 56F. Winds W at 10 to 20 mph.\\\\n\\\\n## Fri 18\\\\n\\\\n## Day\\\\n\\\\nCloudy skies early, followed by partial clearing. High 64F. Winds W at 15 to 25 mph.\\\\n\\\\n## Night\\\\n\\\\nPartly cloudy during the evening followed by cloudy skies overnight. Expect mist and reduced visibilities at times. Low 54F. Winds W at 10 to 20 mph.\\\\n\\\\n## Sat 19\\\\n\\\\n## Day\\\\n\\\\nCloudy early with partial sunshine expected late. High 63F. Winds W at 10 to 20 mph.\\\\n\\\\n## Night [...] Considerable cloudiness. Low 54F. Winds WSW at 10 to 20 mph.\\\\n\\\\n## Sun 20\\\\n\\\\n## Day\\\\n\\\\nIntervals of clouds and sunshine. High near 65F. Winds WSW at 10 to 20 mph.\\\\n\\\\n## Night\\\\n\\\\nClear skies with a few passing clouds. Low around 55F. Winds W at 10 to 20 mph.\\\\n\\\\n## Radar\\\\n\\\\n## Trending Now\\\\n\\\\n## We Love Our Critters\\\\n\\\\n## Summer And Your Skin\\\\n\\\\n## Home, Garage & Garden\\\\n\\\\n## Monster Firenado\\\\n\\\\n## Keeping You Healthy\\\\n\\\\n## Product Reviews & Deals\\\\n\\\\nundefined\\\\n\\\\nBeat The Glare Of A Sunny Day: TVs That Look Like Paintings\"}]', name='tavily_search_results_json', tool_call_id='call_bmfLa92f6oAIKN9KvXtqbKDz')]\n",
      "[AIMessage(content=\"The current weather in San Francisco is as follows:\\n\\n- **Daytime**: Cloudy skies this morning will become partly cloudy this afternoon with a high of 66°F. Winds are from the west at 10 to 20 mph.\\n- **Nighttime**: Partly cloudy skies this evening will become overcast overnight with a low of 56°F. Winds are from the west at 10 to 20 mph.\\n\\nOverall, it's a cloudy day with partial clearing expected later.\", response_metadata={'token_usage': {'completion_tokens': 99, 'prompt_tokens': 1225, 'total_tokens': 1324, 'prompt_tokens_details': {'cached_tokens': 0, 'audio_tokens': 0}, 'completion_tokens_details': {'reasoning_tokens': 0, 'audio_tokens': 0, 'accepted_prediction_tokens': 0, 'rejected_prediction_tokens': 0}}, 'model_name': 'gpt-4o', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-95330626-2d64-47d4-8ffe-56a37cec2164-0')]\n"
     ]
    }
   ],
   "source": [
    "for event in abot.graph.stream({\"messages\": messages}, thread):\n",
    "    for v in event.values():\n",
    "        print(v['messages'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "22aa02bf",
   "metadata": {
    "height": 98
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_9IKDlPoxdS3rHnNGtrw8lupx', 'function': {'arguments': '{\"query\":\"current weather in Los Angeles\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 22, 'prompt_tokens': 1336, 'total_tokens': 1358, 'prompt_tokens_details': {'cached_tokens': 1280, 'audio_tokens': 0}, 'completion_tokens_details': {'reasoning_tokens': 0, 'audio_tokens': 0, 'accepted_prediction_tokens': 0, 'rejected_prediction_tokens': 0}}, 'model_name': 'gpt-4o', 'system_fingerprint': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-f619a852-6722-439b-8068-eedb185eafa8-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'current weather in Los Angeles'}, 'id': 'call_9IKDlPoxdS3rHnNGtrw8lupx'}])]}\n",
      "Calling: {'name': 'tavily_search_results_json', 'args': {'query': 'current weather in Los Angeles'}, 'id': 'call_9IKDlPoxdS3rHnNGtrw8lupx'}\n",
      "Back to the model!\n",
      "{'messages': [ToolMessage(content=\"[{'url': 'https://world-weather.info/forecast/usa/los_angeles/july-2025/', 'content': 'Detailed ⚡ Los Angeles Weather Forecast for July 2025 – day/night 🌡️ ... Thursday, 17 July. +64°. Day. +79°. Clear sky. Friday, 18 July. +64°. Day. +79'}, {'url': 'https://www.weather25.com/north-america/usa/california/los-angeles?page=month&month=July', 'content': 'weather25.com\\\\nSearch\\\\nweather in United States\\\\nRemove from your favorite locations\\\\nAdd to my locations\\\\nShare\\\\nweather in United States\\\\n\\\\n# Los Angeles weather in July 2025\\\\n\\\\nPartly cloudy\\\\nPartly cloudy\\\\nPartly cloudy\\\\nClear\\\\nClear\\\\nClear\\\\nClear\\\\nClear\\\\nClear\\\\nClear\\\\nClear\\\\nPartly cloudy\\\\nPartly cloudy\\\\nClear\\\\n\\\\n## The average weather in Los Angeles in July\\\\n\\\\nThe weather in Los Angeles in July is hot. The average temperatures are between 20°C and 30°C. [...] | 13 Partly cloudy 29° /20° | 14 Sunny 29° /20° | 15 Sunny 29° /20° | 16 Sunny 29° /21° | 17 Partly cloudy 28° /18° | 18 Partly cloudy 29° /17° | 19 Partly cloudy 29° /17° |\\\\n| 20 Sunny 30° /20° | 21 Sunny 29° /20° | 22 Sunny 29° /20° | 23 Sunny 31° /21° | 24 Sunny 31° /22° | 25 Sunny 31° /23° | 26 Sunny 32° /23° |\\\\n| 27 Sunny 35° /24° | 28 Partly cloudy 38° /26° | 29 Partly cloudy 32° /25° | 30 Sunny 33° /24° | 31 Partly cloudy 31° /22° |  |  | [...] | Sun | Mon | Tue | Wed | Thu | Fri | Sat |\\\\n| --- | --- | --- | --- | --- | --- | --- |\\\\n|  |  | 1 Sunny 28° /19° | 2 Sunny 28° /19° | 3 Sunny 28° /19° | 4 Sunny 29° /19° | 5 Sunny 29° /19° |\\\\n| 6 Sunny 29° /20° | 7 Sunny 28° /19° | 8 Cloudy 29° /20° | 9 Sunny 30° /20° | 10 Partly cloudy 31° /21° | 11 Sunny 31° /20° | 12 Sunny 30° /21° |'}]\", name='tavily_search_results_json', tool_call_id='call_9IKDlPoxdS3rHnNGtrw8lupx')]}\n",
      "{'messages': [AIMessage(content='The current weather in Los Angeles is:\\n\\n- **Daytime**: Partly cloudy with a high of around 79°F. \\n- **Nighttime**: Clear skies with a low of about 64°F.\\n\\nOverall, Los Angeles is experiencing a warm day with partly cloudy conditions.', response_metadata={'token_usage': {'completion_tokens': 59, 'prompt_tokens': 1975, 'total_tokens': 2034, 'prompt_tokens_details': {'cached_tokens': 1280, 'audio_tokens': 0}, 'completion_tokens_details': {'reasoning_tokens': 0, 'audio_tokens': 0, 'accepted_prediction_tokens': 0, 'rejected_prediction_tokens': 0}}, 'model_name': 'gpt-4o', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-a9420d7b-7e7e-4fdd-9171-7a067a7a38b1-0')]}\n"
     ]
    }
   ],
   "source": [
    "messages = [HumanMessage(content=\"What about in la?\")]\n",
    "thread = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "for event in abot.graph.stream({\"messages\": messages}, thread):\n",
    "    for v in event.values():\n",
    "        print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0d93d149",
   "metadata": {
    "height": 98
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [AIMessage(content='Currently, Los Angeles is warmer than San Francisco. Los Angeles has a high of around 79°F, while San Francisco has a high of 66°F.', response_metadata={'token_usage': {'completion_tokens': 33, 'prompt_tokens': 2046, 'total_tokens': 2079, 'prompt_tokens_details': {'cached_tokens': 1920, 'audio_tokens': 0}, 'completion_tokens_details': {'reasoning_tokens': 0, 'audio_tokens': 0, 'accepted_prediction_tokens': 0, 'rejected_prediction_tokens': 0}}, 'model_name': 'gpt-4o', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-e4387a0f-c8fa-45db-a7e2-f09bb7d15a02-0')]}\n"
     ]
    }
   ],
   "source": [
    "messages = [HumanMessage(content=\"Which one is warmer?\")]\n",
    "thread = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "for event in abot.graph.stream({\"messages\": messages}, thread):\n",
    "    for v in event.values():\n",
    "        print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "119f3fc3",
   "metadata": {
    "height": 98
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [AIMessage(content=\"Could you please clarify what you're comparing to determine which is warmer? Are you comparing two specific locations, types of clothing, materials, or something else? Let me know so I can provide the appropriate information.\", response_metadata={'token_usage': {'completion_tokens': 43, 'prompt_tokens': 149, 'total_tokens': 192, 'prompt_tokens_details': {'cached_tokens': 0, 'audio_tokens': 0}, 'completion_tokens_details': {'reasoning_tokens': 0, 'audio_tokens': 0, 'accepted_prediction_tokens': 0, 'rejected_prediction_tokens': 0}}, 'model_name': 'gpt-4o', 'system_fingerprint': 'fp_f9f4fb6dbf', 'finish_reason': 'stop', 'logprobs': None}, id='run-4fbf0c1f-a93c-4446-bfb2-c96be8936b3e-0')]}\n"
     ]
    }
   ],
   "source": [
    "messages = [HumanMessage(content=\"Which one is warmer?\")]\n",
    "thread = {\"configurable\": {\"thread_id\": \"2\"}}\n",
    "for event in abot.graph.stream({\"messages\": messages}, thread):\n",
    "    for v in event.values():\n",
    "        print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a29c1bdf",
   "metadata": {
    "height": 81
   },
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.aiosqlite import AsyncSqliteSaver\n",
    "\n",
    "memory = AsyncSqliteSaver.from_conn_string(\":memory:\")\n",
    "abot = Agent(model, [tool], system=prompt, checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c42964c7",
   "metadata": {
    "height": 200
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/langchain_core/_api/beta_decorator.py:87: LangChainBetaWarning: This API is in beta and may change in the future.\n",
      "  warn_beta(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling: {'name': 'tavily_search_results_json', 'args': {'query': 'current weather in San Francisco'}, 'id': 'call_8etfZasfe0eUw99Q9qqzCQ0N'}\n",
      "Back to the model!\n",
      "The| current| weather| in| San| Francisco| is| cloudy|.| The| temperature| is| expected| to| reach| a| high| of| |66|°F| today|,| with| winds| from| the| west| at| |10| to| |20| mph|.| This| afternoon|,| the| skies| will| become| partly| cloudy|.| Tonight|,| the| skies| will| be| partly| cloudy|,| becoming| over|cast| overnight| with| a| low| of| |56|°F|.|"
     ]
    }
   ],
   "source": [
    "messages = [HumanMessage(content=\"What is the weather in SF?\")]\n",
    "thread = {\"configurable\": {\"thread_id\": \"4\"}}\n",
    "async for event in abot.graph.astream_events({\"messages\": messages}, thread, version=\"v1\"):\n",
    "    kind = event[\"event\"]\n",
    "    if kind == \"on_chat_model_stream\":\n",
    "        content = event[\"data\"][\"chunk\"].content\n",
    "        if content:\n",
    "            # Empty content in the context of OpenAI means\n",
    "            # that the model is asking for a tool to be invoked.\n",
    "            # So we only print non-empty content\n",
    "            print(content, end=\"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007dd0f5",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
